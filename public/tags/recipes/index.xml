<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recipes on pRopaganda by smaakagen</title>
    <link>/tags/recipes/</link>
    <description>Recent content in Recipes on pRopaganda by smaakagen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Dec 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/recipes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>One Recipe Step to Rule Them All</title>
      <link>/2018/12/03/one-recipe-step-to-rule-them-all/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/03/one-recipe-step-to-rule-them-all/</guid>
      <description>&lt;p&gt;In this post I will demonstrate, how my new R package &lt;code&gt;customsteps&lt;/code&gt; can be used
to create recipe steps, that apply custom transformations to a data set.&lt;/p&gt;
&lt;p&gt;Note, you should already be fairly familiar with the &lt;a href=&#34;https://cran.r-project.org/web/packages/recipes/recipes.pdf&#34;&gt;&lt;code&gt;recipes&lt;/code&gt;&lt;/a&gt; package
before you continue reading this post or give &lt;code&gt;customsteps&lt;/code&gt; a spin!&lt;/p&gt;
&lt;p&gt;Recommended music for this reading session:&lt;/p&gt;
&lt;iframe src=&#34;https://open.spotify.com/embed/track/323v1HB9ugfmQyqZwFaZwz&#34; width=&#34;300&#34; height=&#34;80&#34; frameborder=&#34;0&#34; allowtransparency=&#34;true&#34; allow=&#34;encrypted-media&#34;&gt;
&lt;/iframe&gt;
&lt;div id=&#34;introducing-the-customsteps-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introducing the &lt;code&gt;customsteps&lt;/code&gt; package&lt;/h2&gt;
&lt;p&gt;Along with the &lt;code&gt;recipes&lt;/code&gt; package distribution comes a number of pre-specified steps, that enables the user to manipulate data sets in various ways. The
resulting data sets (/design matrices) can then be used as inputs
into statistical or machine learning models.&lt;/p&gt;
&lt;p&gt;If you want to apply a specific transformation to your data set, that is not supported by the pre-specified steps, you have two options. You can write an entire &lt;a href=&#34;https://github.com/tidymodels/recipes/blob/master/vignettes/Custom_Steps.Rmd&#34;&gt;custom recipe step &lt;strong&gt;from
scratch&lt;/strong&gt;&lt;/a&gt;. This however takes quite a bit of work and code. An alternative - and sometimes better - approach is to apply the &lt;code&gt;customsteps&lt;/code&gt; package, that I have just released on CRAN.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;customsteps&amp;quot;)
library(customsteps)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;customizable-higher-order-steps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Customizable Higher-Order Steps&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;customsteps&lt;/code&gt; contains a set of customizable higher-order recipe step
functions, that create specifications of recipe steps, that will transform or filter the data in accordance with custom input functions.&lt;/p&gt;
&lt;p&gt;Let me just remind you of the definition of &lt;a href=&#34;https://en.wikipedia.org/wiki/Higher-order_function&#34;&gt;&lt;strong&gt;higher-order functions&lt;/strong&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;In mathematics and computer science, a higher-order function is a function that does at least one of the following: 1. takes one or more functions as arguments,
2. returns a function as its result.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Next, I will present an example of how to use the &lt;code&gt;customsteps&lt;/code&gt; package in order
to create a recipe step, that will apply a custom transformation to a data set.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case-centering-and-scaling-numeric-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use Case: Centering and Scaling Numeric Data&lt;/h2&gt;
&lt;p&gt;Assume, that I want to transform a variable &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Center &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; around an arbitrary number &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Scale the transformed variable, such that its standard deviation equals an
arbitrary number &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The transformed variable &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{x}}\)&lt;/span&gt; can then be derived as (try to
do it yourself):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{x}} = \alpha + (\mathbf{x} - \bar{\mathbf{x}})\frac{\beta}{s_\mathbf{x}}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{\mathbf{x}}\)&lt;/span&gt; is the mean of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt;, and
&lt;span class=&#34;math inline&#34;&gt;\(s_\mathbf{x}\)&lt;/span&gt; is the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that centering &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; around 0 and scaling it in order to arrive at a standard deviation of 1 is just a special case of the above transformation with parameters &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0, \beta = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;write-the-prep-helper-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Write the &lt;code&gt;prep&lt;/code&gt; helper function&lt;/h3&gt;
&lt;p&gt;First, I need to write a function, that estimates the relevant statistical
parameters from an initial data set. I call this function the &lt;code&gt;prep&lt;/code&gt; helper
function.&lt;/p&gt;
&lt;p&gt;Obviously, the above transformation requires the mean &lt;span class=&#34;math inline&#34;&gt;\(\bar{\mathbf{x}}\)&lt;/span&gt; and
standard deviation &lt;span class=&#34;math inline&#34;&gt;\(s_\mathbf{x}\)&lt;/span&gt; to be learned from the initial data set.
Therefore I define a function &lt;code&gt;compute_means_sd&lt;/code&gt;, that estimates the two
parameters for (any arbitrary number of) numeric variables.&lt;/p&gt;
&lt;p&gt;By convention the &lt;code&gt;prep&lt;/code&gt; helper function must take the argument &lt;code&gt;x&lt;/code&gt;: the subset of
selected variables from the initial data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)

compute_means_sd &amp;lt;- function(x) {
  
  map(.x = x, ~ list(mean = mean(.x), sd = sd(.x)))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us see the function in action. I will apply it to a subset of the famous
&lt;code&gt;mtcars&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

# divide &amp;#39;mtcars&amp;#39; into two data sets.
cars_initial &amp;lt;- mtcars[1:16, ]
cars_new &amp;lt;- mtcars[17:nrow(mtcars), ]

# learn parameters from initial data set.
params &amp;lt;- cars_initial %&amp;gt;%
  select(mpg, disp) %&amp;gt;%
  compute_means_sd(.)

# display parameters. 
as.data.frame(params)
#&amp;gt;   mpg.mean  mpg.sd disp.mean disp.sd
#&amp;gt; 1     18.2 4.14761  250.8187 113.372&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It works like a charm. Great, we are halfway there!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;write-the-bake-helper-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Write the &lt;code&gt;bake&lt;/code&gt; helper function&lt;/h3&gt;
&lt;p&gt;Second, I have to specify a &lt;code&gt;bake&lt;/code&gt; helper function, that defines how to apply
the transformation to a new data set using the parameters estimated from the
intial data set.&lt;/p&gt;
&lt;p&gt;By convention the &lt;code&gt;bake&lt;/code&gt; helper function must take the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt;: the new data set, that the step will be applied to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prep_output&lt;/code&gt;: the output from the &lt;code&gt;prep&lt;/code&gt; helper function containing
any parameters estimated from the initial data set.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I define the function &lt;code&gt;center_scale&lt;/code&gt;, that will serve as my &lt;code&gt;bake&lt;/code&gt; helper
function. It will center and scale variables of a new data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;center_scale &amp;lt;- function(x, prep_output, alpha, beta) {

  # extract only the relevant variables from the new data set.
  new_data &amp;lt;- select(x, names(prep_output))

  # apply transformation to each of these variables.
  # variables are centered around &amp;#39;alpha&amp;#39; and scaled to have a standard 
  # deviation of &amp;#39;beta&amp;#39;.
  map2(.x = new_data,
       .y = prep_output,
       ~ alpha + (.x - .y$mean) * beta / .y$sd)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My first (sanity) check of the function is to
apply it to the initial data set, that was used for estimation of
the means and standard deviations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tibble)
# center and scale variables of new data set to have a mean of zero
# and a standard deviation of one.
cars_initial_transformed &amp;lt;- center_scale(x = cars_initial, 
                                         prep_output = params,
                                         alpha = 0, 
                                         beta = 1)

# display transformed variables.
cars_initial_transformed %&amp;gt;%
  compute_means_sd(.) %&amp;gt;%
  as.data.frame(.)
#&amp;gt;       mpg.mean mpg.sd    disp.mean disp.sd
#&amp;gt; 1 1.731877e-16      1 7.199102e-17       1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Results are correct within computational precision.&lt;/p&gt;
&lt;p&gt;Also, I will just check the function out on the other subset of &lt;code&gt;mtcars&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# center and scale variables of new data set to have a mean of zero
# and a standard deviation of one.
cars_new_transformed &amp;lt;- center_scale(x = cars_new, 
                                     prep_output = params,
                                     alpha = 0, 
                                     beta = 1)

# display transformed variables.
cars_new_transformed %&amp;gt;%
  as.tibble(.) %&amp;gt;%
  head(.)
#&amp;gt; # A tibble: 6 x 2
#&amp;gt;      mpg   disp
#&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
#&amp;gt; 1 -0.844  1.67 
#&amp;gt; 2  3.42  -1.52 
#&amp;gt; 3  2.94  -1.54 
#&amp;gt; 4  3.79  -1.59 
#&amp;gt; 5  0.796 -1.15 
#&amp;gt; 6 -0.651  0.593&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks right! All that is left now is to put the pieces together into my new
very own custom recipe step.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-the-pieces-together&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Putting the pieces together&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;step_custom_transformation&lt;/code&gt; takes &lt;code&gt;prep&lt;/code&gt; and &lt;code&gt;bake&lt;/code&gt; helper
functions as inputs and turns them into a complete recipe step, that can be used
out of the box.&lt;/p&gt;
&lt;p&gt;I create the specification of the recipe step from the new functions &lt;code&gt;compute_means_sd&lt;/code&gt; and
&lt;code&gt;center_scale&lt;/code&gt; by invoking &lt;code&gt;step_custom_transformation&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(recipes)
rec &amp;lt;- recipe(cars_initial) %&amp;gt;%
  step_custom_transformation(mpg, disp,
                             prep_function = compute_means_sd,
                             bake_function = center_scale,
                             bake_options = list(alpha = 0, beta = 1),
                             bake_how = &amp;quot;replace&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that is all there is to it! Easy.&lt;/p&gt;
&lt;p&gt;Note, by setting ‘bake_options’ to “replace”, the
selected terms will be replaced with the transformed variables, when the
recipe is baked.&lt;/p&gt;
&lt;p&gt;I will just check, that the recipe works as expected. First I will &lt;code&gt;prep&lt;/code&gt;(/train)
the recipe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# prep recipe.
rec &amp;lt;- prep(rec)

# print recipe.
rec
#&amp;gt; Data Recipe
#&amp;gt; 
#&amp;gt; Inputs:
#&amp;gt; 
#&amp;gt;   11 variables (no declared roles)
#&amp;gt; 
#&amp;gt; Training data contained 16 data points and no missing data.
#&amp;gt; 
#&amp;gt; Operations:
#&amp;gt; 
#&amp;gt; The following variables are used for computing transformations
#&amp;gt;  and will be dropped afterwards:
#&amp;gt;  mpg, disp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will go right ahead and bake the new recipe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bake recipe.
cars_baked &amp;lt;- rec %&amp;gt;%
  bake(cars_new) %&amp;gt;%
  select(mpg, disp)
  
# display results.
cars_baked %&amp;gt;%
  head(.)
#&amp;gt; # A tibble: 6 x 2
#&amp;gt;      mpg   disp
#&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
#&amp;gt; 1 -0.844  1.67 
#&amp;gt; 2  3.42  -1.52 
#&amp;gt; 3  2.94  -1.54 
#&amp;gt; 4  3.79  -1.59 
#&amp;gt; 5  0.796 -1.15 
#&amp;gt; 6 -0.651  0.593&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Results are as expected (same as before). Great succes!&lt;/p&gt;
&lt;p&gt;You should now be able
to create your very own recipe steps to do (almost) whatever
transformation you want to your data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Customized recipe steps can be created with a minimum of effort and code using
my new R package &lt;code&gt;customsteps&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;customsteps&lt;/code&gt; step functions are higher-order functions,
that create specificiations of recipe steps from custom input functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please let me hear from you, if you have any feedback on the package.&lt;/p&gt;
&lt;p&gt;Best,
smaakagen&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tuning a data preprocessing pipeline with recipes and modelgrid</title>
      <link>/2018/09/24/tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/24/tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid/</guid>
      <description>&lt;p&gt;In this post I will demonstrate, how the &lt;a href=&#34;https://cran.r-project.org/web/packages/modelgrid/index.html&#34;&gt;&lt;code&gt;modelgrid&lt;/code&gt;&lt;/a&gt; package can be used
to facilitate experiments with the data preprocessing pipeline of a
predictive model.&lt;/p&gt;
&lt;div id=&#34;data-preprocessing---an-integral-part-of-a-model-configuration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data preprocessing - an integral part of a model configuration&lt;/h2&gt;
&lt;p&gt;Model tuning is not just a matter of tuning the hyperparameters of an algorithm.
Since data preprocessing is also an integral part of the model development
workflow, it is just as relevant to experiment with the data preprocessing pipeline
of a model configuration.
When “tuning” a model, the data preprocessing pipeline should therefore also be tuned.&lt;/p&gt;
&lt;p&gt;In the following I will present an example of tuning a data preprocessing
pipeline using &lt;code&gt;modelgrid&lt;/code&gt; in combination with &lt;a href=&#34;https://github.com/tidymodels/recipes&#34;&gt;&lt;code&gt;recipes&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case-cell-segmentation-in-high-content-screening&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use case: Cell Segmentation in High-Content Screening&lt;/h2&gt;
&lt;p&gt;I will use the Cell Segmentation data set described in the excellent book
&lt;a href=&#34;http://appliedpredictivemodeling.com/&#34;&gt;&lt;strong&gt;‘Applied Predictive Modelling’&lt;/strong&gt;&lt;/a&gt; as
an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AppliedPredictiveModeling)
#&amp;gt; Warning: pakke &amp;#39;AppliedPredictiveModeling&amp;#39; blev bygget under R version
#&amp;gt; 3.6.1
data(segmentationOriginal)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data set consists of 2019 samples, where each
sample represents a cell. Of these cells,
1300 were judged to be poorly segmented
and 719 were well segmented;
1009 cells were reserved for the
training set.&lt;/p&gt;
&lt;p&gt;In each cell 116 measurements were taken. They are all
available as numeric predictors.&lt;/p&gt;
&lt;p&gt;For more information on the data set look &lt;a href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-340&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Our goal is to develop a classification model, that separates the poorly
segmented from the well segmented cells.&lt;/p&gt;
&lt;div id=&#34;data-at-a-glance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data at a glance&lt;/h3&gt;
&lt;p&gt;First, let us take a quick look at the data. We will do that by inspecting the between-predictor
correlations of the predictors expressed by a correlation matrix of the
training data set. The variables are grouped adjacent to each other according to their mutual
correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract training data.
training &amp;lt;- filter(segmentationOriginal, Case == &amp;quot;Train&amp;quot;)

# Extract predictors.
predictors &amp;lt;- training %&amp;gt;% select(-(c(&amp;quot;Class&amp;quot;, &amp;quot;Case&amp;quot;, &amp;quot;Cell&amp;quot;))) 

# Identify variables with zero variance.
zero_variance_predictors &amp;lt;- map_lgl(predictors, ~ n_distinct(.x) == 1)

# Remove predictors with zero variance.
predictors &amp;lt;- predictors[, !zero_variance_predictors]

# Compute and plot a correlation matrix of remaining predictors.
library(corrplot)
predictors %&amp;gt;%
  cor(.) %&amp;gt;%
  corrplot(., order = &amp;quot;hclust&amp;quot;, tl.cex = .35)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the graph, it seems that there are groups of predictors, that have strong
positive correlations (dark blue).&lt;/p&gt;
&lt;p&gt;There can be good reasons for avoiding variables, that are highly correlated, some
of them being (as stated in &lt;a href=&#34;http://appliedpredictivemodeling.com/&#34;&gt;&lt;strong&gt;‘Applied Predictive Modelling’&lt;/strong&gt;&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redundant/highly correlated predictors often add more complexity than information to the model&lt;/li&gt;
&lt;li&gt;Mathematical disadvantages: can result in very unstable models (high variance),
numerical errors and inferior predictive performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The aim of my modelling experiments will be to apply different preprocessing techniques
in order to mitigate the potential pitfalls of the “collinearity clusters”, that we
are observing amongst the field of predictors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-initial-recipe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create initial recipe&lt;/h3&gt;
&lt;p&gt;First, let us set up a starting point for our data preprocessing pipeline in
our modeling experiments. For this purpose I apply the &lt;strong&gt;awesome&lt;/strong&gt; &lt;code&gt;recipes&lt;/code&gt;
package and create a - very basic - recipe, that will serve as an anchor for my
model configurations.&lt;/p&gt;
&lt;p&gt;In this recipe I declare the roles of all variables in the data set and state,
that variables with zero variances should be removed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(recipes)
initial_recipe &amp;lt;- recipe(training) %&amp;gt;%
  update_role(Class, new_role = &amp;quot;outcome&amp;quot;) %&amp;gt;%
  update_role(Cell, new_role = &amp;quot;id variable&amp;quot;) %&amp;gt;%
  update_role(Case, new_role = &amp;quot;splitting indicator&amp;quot;) %&amp;gt;%
  update_role(-Class, -Cell, -Case, new_role = &amp;quot;predictor&amp;quot;) %&amp;gt;%
  step_zv(all_predictors())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can ‘prep’ the recipe and get an impression of, what it is actually doing.
It seems, it removes two of the predictors due to them having variances of zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prep_rec &amp;lt;- prep(initial_recipe)
tidy(prep_rec, 1)
#&amp;gt; # A tibble: 2 x 2
#&amp;gt;   terms                        id      
#&amp;gt;   &amp;lt;chr&amp;gt;                        &amp;lt;chr&amp;gt;   
#&amp;gt; 1 MemberAvgAvgIntenStatusCh2   zv_hHSqi
#&amp;gt; 2 MemberAvgTotalIntenStatusCh2 zv_hHSqi&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-a-model-grid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Set up a model grid&lt;/h3&gt;
&lt;p&gt;In order to organize and structure my experiments with different data
preprocessing pipelines I apply my &lt;a href=&#34;https://github.com/smaakage85/modelgrid&#34;&gt;&lt;code&gt;modelgrid&lt;/code&gt;&lt;/a&gt;
package, that offers &lt;a href=&#34;http://smaakage85.netlify.com/2018/07/14/modelgrid-a-framework-for-creating-managing-and-training-multiple-models/&#34;&gt;a framework for constructing, training and managing multiple
&lt;code&gt;caret&lt;/code&gt; models&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;modelgrid&lt;/code&gt; separates the specification of a(ny number of) &lt;code&gt;caret&lt;/code&gt; model(s) from
the training/estimation of the model(s). By doing so, &lt;code&gt;modelgrid&lt;/code&gt; follows the same
principles as the new promising package &lt;a href=&#34;https://github.com/topepo/parsnip&#34;&gt;&lt;code&gt;parsnip&lt;/code&gt;&lt;/a&gt;,
which is under construction.&lt;/p&gt;
&lt;p&gt;Assume, that we want to estimate a family of Generalized Linear Models, all with different
data preprocessing pipelines. I have decided on the following conditions for the
model training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply a cross-validation resampling scheme with 5 folds.&lt;/li&gt;
&lt;li&gt;Tune the models and measure performance using the standard and highly versatile
‘Area Under the Curve’ (AUC(/ROC)) metric.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I construct a &lt;strong&gt;model_grid&lt;/strong&gt; and set the settings, that by default will apply
to all of my models, accordingly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelgrid)
library(caret)

models &amp;lt;- 
  # create empty model grid with constructor function.
  model_grid() %&amp;gt;%
  # set shared settings, that will apply to all models by default.
  share_settings(
    data = training,
    trControl = trainControl(method = &amp;quot;cv&amp;quot;,
                             number = 5,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE),
    metric = &amp;quot;ROC&amp;quot;,
    method = &amp;quot;glm&amp;quot;,
    family = binomial(link = &amp;quot;logit&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready to add individual model specifications, each with their own
data preprocessing pipeline to the model grid.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-the-first-model-specifications-to-the-model-grid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding the first model specifications to the model grid&lt;/h3&gt;
&lt;p&gt;We will kick things off by adding the first model specification to my model grid.
In this configuration I just apply our initial data preprocessing recipe and do
no further. I will refer to this model as ‘baseline’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;baseline&amp;quot;, 
            x = initial_recipe)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One way of dealing with the potential drawbacks of the observed “collinearity clusters”
is to apply a correlation filter. The correlation filter poses a heuristic
approach to dealing with highly correlated predictors.
It removes the predictors with the highest between-predictor correlations one at
a time, until all between-predictor correlations are below some critical threshold.&lt;/p&gt;
&lt;p&gt;In order to do so, I extend my initial recipe with an additional step, that applies
the correlation filter. Furthermore I will try out different values for the
between-predictor correlation threshold value of the filter, essentially
treating it as a hyperparameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.7&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .7)) %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.8&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .8)) %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.9&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The construction of these model specifications can - and indeed
should - be parametrized. Especially if you want to try
out a wider range of values for the ‘threshold’ parameter than just
the three, that I have denoted here.&lt;/p&gt;
&lt;p&gt;Great, now we have a bunch of models specifications. We will train them
right away and take a first look at the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train models.
models &amp;lt;- models %&amp;gt;% train(.)
# Display resampled performance statistics of the fitted models using standard 
# functionality from the &amp;#39;caret&amp;#39; package.
models$model_fits %&amp;gt;% resamples(.) %&amp;gt;% bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Judging by the resampled AUC performance statistics it seems, that there
&lt;em&gt;could&lt;/em&gt; be a case for applying a correlation filter on the set of
predictors. Apparently, the model with a correlation filter with a
between-predictor correlation threshold value of .7 added to the data
preprocessing pipeline yields the best median resampled AUC. Of the four models,
this model is by far the least complex.&lt;/p&gt;
&lt;p&gt;We can see this by taking a look at the number of predictors, that
were actually used in the final models (after removing variables
with a correlation filter (if any)).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models$model_fits %&amp;gt;%
  map(pluck(c(&amp;quot;recipe&amp;quot;, &amp;quot;term_info&amp;quot;, &amp;quot;role&amp;quot;))) %&amp;gt;%
  map_int(~ sum(.x == &amp;quot;predictor&amp;quot;))
#&amp;gt; baseline  corr_.7  corr_.8  corr_.9 
#&amp;gt;      114       60       78       93&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ‘corr_.7’ model configuration only uses 60 predictors (after
removal of highly correlated predictors), hence it only estimates
61 coefficients. In contrast the ‘baseline’ model uses all predictors
(except the two variables with zero variances) and estimates 115
coefficients in total making it a much more complex model (by means
of a higher variance) and more prone to the risk of overfitting.&lt;/p&gt;
&lt;p&gt;Overall it seems like applying a correlation filter with a correlation
threshold value of 0.7 as part of the data preprocessing pipeline could
be a good idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dimensionality-reduction-with-pca&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dimensionality reduction with PCA&lt;/h3&gt;
&lt;p&gt;Another approach to dealing with highly correlated predictors is
to apply a Principal Component Analysis transformation of the
predictors in order to reduce the dimensions of data set. You can read
more about the PCA technique &lt;a href=&#34;https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This approach can be tested by tweaking my initial data preprocessing
recipe once again with a couple of additional steps. Before actually
conducting PCA, features are centered and scaled. This is completely
standard.&lt;/p&gt;
&lt;p&gt;For the PCA transformation I vary the ‘threshold’ value, which
is the fraction of the total variance of the predictors that should be
covered by the components. The higher the value of ‘threshold’, the
higher the number of components used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extend recipe with centering and scaling steps.
rec_center_scale &amp;lt;- initial_recipe %&amp;gt;%
  step_center(all_predictors()) %&amp;gt;%
  step_scale(all_predictors())

# Add model specifications with pca for dimensionality reduction.
models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.75&amp;quot;, 
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .75)) %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.85&amp;quot;,
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .85)) %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.95&amp;quot;,
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .95))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us train the new model configurations and display the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- train(models)
models$model_fits %&amp;gt;% caret::resamples(.) %&amp;gt;% bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Applying a data preprocessing pipeline with a PCA transformation
capturing 95 pct. of the total variance of the set of predictors
actually returns the highest resampled median value of AUC.&lt;/p&gt;
&lt;p&gt;You can look up, how many principal components that were
used in the different model configurations in order to account
for the desired amount of total variance of the predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models$model_fits[c(&amp;quot;pca_.75&amp;quot;, &amp;quot;pca_.85&amp;quot;, &amp;quot;pca_.95&amp;quot;)] %&amp;gt;%
  map(pluck(c(&amp;quot;recipe&amp;quot;, &amp;quot;term_info&amp;quot;, &amp;quot;role&amp;quot;))) %&amp;gt;%
  map_int(~ sum(.x == &amp;quot;predictor&amp;quot;))
#&amp;gt; pca_.75 pca_.85 pca_.95 
#&amp;gt;      22      34      58&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To summarize, adding a PCA transformation or a correlation filter
to the data preprocessing pipeline seem like good ways of
dealing with the “collinearity clusters” in the data set.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Experimenting with the data preprocessing pipeline can be seen as part of the
model tuning process. Parameters of the data preprocessing pipeline can be thought
of as tuning parameters.&lt;/li&gt;
&lt;li&gt;These kinds of experiments can be organized and conducted easily using R packages
&lt;code&gt;recipes&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; in combination with &lt;code&gt;modelgrid&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-next&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;I have been thinking about how to extend the functionality of &lt;code&gt;modelgrid&lt;/code&gt; further
in order to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parametrize experiments with the parameters of the data preprocessing
pipeline. But actually I was under the impression, that others are working on
developing similar functionality for tuning parameters of the data preprocessing
pipeline. Am I wrong here?&lt;/li&gt;
&lt;li&gt;Support &lt;code&gt;parsnip&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;To expose models and model configurations from a model grid in a more ‘tidy’ way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Best,
smaakagen&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>