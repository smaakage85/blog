<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modelgrid on pRopaganda by smaakagen</title>
    <link>/tags/modelgrid/</link>
    <description>Recent content in Modelgrid on pRopaganda by smaakagen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 04 Nov 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/modelgrid/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>One &#39;recipes&#39; Step to Rule Them All</title>
      <link>/2018/11/04/one-recipes-step-to-rule-them-all/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/04/one-recipes-step-to-rule-them-all/</guid>
      <description>&lt;p&gt;In this post I will demonstrate, how my new R package &lt;code&gt;customsteps&lt;/code&gt; can be used to generate &lt;code&gt;recipes&lt;/code&gt; steps, that apply custom transformations to a data set.&lt;/p&gt;
&lt;p&gt;Note, you should already be fairly familiar with the &lt;code&gt;recipes&lt;/code&gt; package before reading this post or giving &lt;code&gt;customsteps&lt;/code&gt; a spin!&lt;/p&gt;
&lt;div id=&#34;introducing-the-customsteps-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introducing the ‘customsteps’ package&lt;/h2&gt;
&lt;p&gt;If you want to apply a transformation to your data set, that is not supported by the pre-specified steps, that come along with the &lt;code&gt;recipes&lt;/code&gt; package distribution, you have two options. You could write an entire &lt;a href=&#34;https://github.com/tidymodels/recipes/blob/master/vignettes/Custom_Steps.Rmd&#34;&gt;custom &lt;code&gt;recipes&lt;/code&gt; step &lt;strong&gt;from scratch&lt;/strong&gt;&lt;/a&gt;, that conducts the specific transformation. This however takes quite a bit of work and code. An alternative - and sometimes better - approach is to apply the &lt;code&gt;customsteps&lt;/code&gt; package, that I have just released on CRAN.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;customsteps&amp;quot;)
library(customsteps)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;customizable-higher-order-steps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Customizable Higher-Order Steps&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;customsteps&lt;/code&gt; contains a set of customizable higher-order &lt;code&gt;recipes&lt;/code&gt; &lt;code&gt;step&lt;/code&gt; functions, that create specifications of recipe steps, that will transform or filter the data in accordance with the input functions. Let me just remind you of the definition of &lt;a href=&#34;https://en.wikipedia.org/wiki/Higher-order_function&#34;&gt;&lt;strong&gt;higher-order functions&lt;/strong&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;In mathematics and computer science, a higher-order function is a function that does at least one of the following: 1. takes one or more functions as arguments, 2. returns a function as its result.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the following I will present an example of how to use the &lt;code&gt;step_custom_transformation&lt;/code&gt; function from the &lt;code&gt;customsteps&lt;/code&gt; package in order to create a specification of a recipe step, that will apply a custom transformation on a data set.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case-centering-and-scaling-numeric-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use Case: Centering and Scaling Numeric Data&lt;/h2&gt;
&lt;p&gt;Assume, that we want to transform a variable &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Center &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; around an arbitrary number &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Scale the transformed variable, such that its standard deviation equals an arbitrary number &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The transformed variable &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{x}}\)&lt;/span&gt; can then be derived as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{x}} = \alpha + (\mathbf{x} - \bar{\mathbf{x}})\frac{\beta}{s_\mathbf{x}}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{\mathbf{x}}\)&lt;/span&gt; is the mean of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(s_\mathbf{x}\)&lt;/span&gt; is the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;, that centering &lt;span class=&#34;math inline&#34;&gt;\({\mathbf{x}}\)&lt;/span&gt; around 0 and scaling it to arrive at a standard deviation of 1 is just a special case of the above transformation with &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0, \beta = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;helper-function-for-the-prep-method&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Helper Function for the &lt;code&gt;prep&lt;/code&gt; method&lt;/h3&gt;
&lt;p&gt;If the transformation requires learning parameters from the ‘training data’, one has to define a helper function for the &lt;code&gt;prep&lt;/code&gt; method of &lt;code&gt;step_custom_transformation&lt;/code&gt;. The job of this function is to learn the parameters, that will be used to transform a new data set.&lt;/p&gt;
&lt;p&gt;Obviously, the above transformation requires the mean &lt;span class=&#34;math inline&#34;&gt;\(\bar{\mathbf{x}}\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(s_\mathbf{x}\)&lt;/span&gt; to be learned from the ‘training data’. Therefore we will write a function &lt;code&gt;compute_means_sd&lt;/code&gt;, that takes an argument &lt;code&gt;x&lt;/code&gt; - the ‘training data’ - as input and learns the two parameters for each variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)

compute_means_sd &amp;lt;- function(x) {
  
  map(.x = x, ~ list(mean = mean(.x), sd = sd(.x)))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, we are halfway there!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;helper-function-for-the-bake-method&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Helper Function for the &lt;code&gt;bake&lt;/code&gt; method&lt;/h3&gt;
&lt;p&gt;Likewise we have to specify a helper function for the &lt;code&gt;bake&lt;/code&gt; method for &lt;code&gt;step_custom_transformation&lt;/code&gt;, that defines the transformation itself and how it should be applied to a new dataset using the parameters learned from the ‘training data’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
center_scale &amp;lt;- function(x, prep_output, alpha, beta) {

  # extract only the relevant variables from the new data set.
  newdata &amp;lt;- select(x, names(prep_output))

  # apply transformation on each of these variables.
  map2(.x = newdata,
       .y = prep_output,
       ~ alpha + (.x - .y$mean) * beta / .y$sd)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are all set to create a recipe drawing on the new transformation for the &lt;code&gt;mtcars&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(recipes)
rec &amp;lt;- recipe(mtcars) %&amp;gt;%
  step_custom_transformation(mpg, disp, hp,
                             prep_function = compute_means_sd,
                             bake_function = center_scale,
                             bake_options = list(alpha = 100, beta = 25),
                             bake_how = &amp;quot;bind_cols&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prep and bake recipe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rec_prep &amp;lt;- prep(rec)
rec_baked &amp;lt;- bake(rec_prep, mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Display results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
mean = map_dbl(rec_baked, mean),
sd = map_dbl(rec_baked, sd)
)
#&amp;gt; # A tibble: 2 x 14
#&amp;gt;     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb  mpg1
#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1 20.1   6.19  231. 147.  3.60  3.22  17.8  0.438 0.406 3.69   2.81  100 
#&amp;gt; 2  6.03  1.79  124.  68.6 0.535 0.978  1.79 0.504 0.499 0.738  1.62   25.
#&amp;gt; # ... with 2 more variables: disp1 &amp;lt;dbl&amp;gt;, hp1 &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tuning a data preprocessing pipeline with recipes and modelgrid</title>
      <link>/2018/09/24/tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/24/tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid/</guid>
      <description>&lt;p&gt;In this post I will demonstrate, how the &lt;a href=&#34;https://cran.r-project.org/web/packages/modelgrid/index.html&#34;&gt;&lt;code&gt;modelgrid&lt;/code&gt;&lt;/a&gt; package can be used to facilitate experiments with the data preprocessing pipeline of a predictive model.&lt;/p&gt;
&lt;div id=&#34;data-preprocessing---an-integral-part-of-a-model-configuration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data preprocessing - an integral part of a model configuration&lt;/h2&gt;
&lt;p&gt;Model tuning is not just a matter of tuning the hyperparameters of an algorithm. Since data preprocessing is also an integral part of the model development workflow, it is just as relevant to experiment with the data preprocessing pipeline of a model configuration. When “tuning” a model, the data preprocessing pipeline should therefore also be tuned.&lt;/p&gt;
&lt;p&gt;In the following I will present an example of tuning a data preprocessing pipeline using &lt;code&gt;modelgrid&lt;/code&gt; in combination with &lt;a href=&#34;https://github.com/tidymodels/recipes&#34;&gt;&lt;code&gt;recipes&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-case-cell-segmentation-in-high-content-screening&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use case: Cell Segmentation in High-Content Screening&lt;/h2&gt;
&lt;p&gt;I will use the Cell Segmentation data set described in the excellent book &lt;a href=&#34;http://appliedpredictivemodeling.com/&#34;&gt;&lt;strong&gt;‘Applied Predictive Modelling’&lt;/strong&gt;&lt;/a&gt; as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AppliedPredictiveModeling)
#&amp;gt; Warning: pakke &amp;#39;AppliedPredictiveModeling&amp;#39; blev bygget under R version
#&amp;gt; 3.5.1
data(segmentationOriginal)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data set consists of 2019 samples, where each sample represents a cell. Of these cells, 1300 were judged to be poorly segmented and 719 were well segmented; 1009 cells were reserved for the training set.&lt;/p&gt;
&lt;p&gt;In each cell 116 measurements were taken. They are all available as numeric predictors.&lt;/p&gt;
&lt;p&gt;For more information on the data set look &lt;a href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-340&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Our goal is to develop a classification model, that separates the poorly segmented from the well segmented cells.&lt;/p&gt;
&lt;div id=&#34;data-at-a-glance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data at a glance&lt;/h3&gt;
&lt;p&gt;First, let us take a quick look at the data. We will do that by inspecting the between-predictor correlations of the predictors expressed by a correlation matrix of the training data set. The variables are grouped adjacent to each other according to their mutual correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract training data.
training &amp;lt;- filter(segmentationOriginal, Case == &amp;quot;Train&amp;quot;)

# Extract predictors.
predictors &amp;lt;- training %&amp;gt;% select(-(c(&amp;quot;Class&amp;quot;, &amp;quot;Case&amp;quot;, &amp;quot;Cell&amp;quot;))) 

# Identify variables with zero variance.
zero_variance_predictors &amp;lt;- map_lgl(predictors, ~ n_distinct(.x) == 1)

# Remove predictors with zero variance.
predictors &amp;lt;- predictors[, !zero_variance_predictors]

# Compute and plot a correlation matrix of remaining predictors.
library(corrplot)
predictors %&amp;gt;%
  cor(.) %&amp;gt;%
  corrplot(., order = &amp;quot;hclust&amp;quot;, tl.cex = .35)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the graph, it seems that there are groups of predictors, that have strong positive correlations (dark blue).&lt;/p&gt;
&lt;p&gt;There can be good reasons for avoiding variables, that are highly correlated, some of them being (as stated in &lt;a href=&#34;http://appliedpredictivemodeling.com/&#34;&gt;&lt;strong&gt;‘Applied Predictive Modelling’&lt;/strong&gt;&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redundant/highly correlated predictors often add more complexity than information to the model&lt;/li&gt;
&lt;li&gt;Mathematical disadvantages: can result in very unstable models (high variance), numerical errors and inferior predictive performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The aim of my modelling experiments will be to apply different preprocessing techniques in order to mitigate the potential pitfalls of the “collinearity clusters”, that we are observing amongst the field of predictors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-initial-recipe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create initial recipe&lt;/h3&gt;
&lt;p&gt;First, let us set up a starting point for our data preprocessing pipeline in our modeling experiments. For this purpose I apply the &lt;strong&gt;awesome&lt;/strong&gt; &lt;code&gt;recipes&lt;/code&gt; package and create a - very basic - recipe, that will serve as an anchor for my model configurations.&lt;/p&gt;
&lt;p&gt;In this recipe I declare the roles of all variables in the data set and state, that variables with zero variances should be removed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(recipes)
initial_recipe &amp;lt;- recipe(training) %&amp;gt;%
  add_role(Class, new_role = &amp;quot;outcome&amp;quot;) %&amp;gt;%
  add_role(Cell, new_role = &amp;quot;id variable&amp;quot;) %&amp;gt;%
  add_role(Case, new_role = &amp;quot;splitting indicator&amp;quot;) %&amp;gt;%
  add_role(-Class, -Cell, -Case, new_role = &amp;quot;predictor&amp;quot;) %&amp;gt;%
  step_zv(all_predictors())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can ‘prep’ the recipe and get an impression of, what it is actually doing. It seems, it removes two of the predictors due to them having variances of zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prep_rec &amp;lt;- prep(initial_recipe)
tidy(prep_rec, 1)
#&amp;gt; # A tibble: 2 x 2
#&amp;gt;   terms                        id      
#&amp;gt;   &amp;lt;chr&amp;gt;                        &amp;lt;chr&amp;gt;   
#&amp;gt; 1 MemberAvgAvgIntenStatusCh2   zv_kDdF1
#&amp;gt; 2 MemberAvgTotalIntenStatusCh2 zv_kDdF1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-a-model-grid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Set up a model grid&lt;/h3&gt;
&lt;p&gt;In order to organize and structure my experiments with different data preprocessing pipelines I apply my &lt;a href=&#34;https://github.com/smaakage85/modelgrid&#34;&gt;&lt;code&gt;modelgrid&lt;/code&gt;&lt;/a&gt; package, that offers &lt;a href=&#34;http://smaakage85.netlify.com/2018/07/14/modelgrid-a-framework-for-creating-managing-and-training-multiple-models/&#34;&gt;a framework for constructing, training and managing multiple &lt;code&gt;caret&lt;/code&gt; models&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;modelgrid&lt;/code&gt; separates the specification of a(ny number of) &lt;code&gt;caret&lt;/code&gt; model(s) from the training/estimation of the model(s). By doing so, &lt;code&gt;modelgrid&lt;/code&gt; follows the same principles as the new promising package &lt;a href=&#34;https://github.com/topepo/parsnip&#34;&gt;&lt;code&gt;parsnip&lt;/code&gt;&lt;/a&gt;, which is under construction.&lt;/p&gt;
&lt;p&gt;Assume, that we want to estimate a family of Generalized Linear Models, all with different data preprocessing pipelines. I have decided on the following conditions for the model training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply a cross-validation resampling scheme with 5 folds.&lt;/li&gt;
&lt;li&gt;Tune the models and measure performance using the standard and highly versatile ‘Area Under the Curve’ (AUC(/ROC)) metric.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I construct a &lt;strong&gt;model_grid&lt;/strong&gt; and set the settings, that by default will apply to all of my models, accordingly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelgrid)
library(caret)

models &amp;lt;- 
  # create empty model grid with constructor function.
  model_grid() %&amp;gt;%
  # set shared settings, that will apply to all models by default.
  share_settings(
    data = training,
    trControl = trainControl(method = &amp;quot;cv&amp;quot;,
                             number = 5,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE),
    metric = &amp;quot;ROC&amp;quot;,
    method = &amp;quot;glm&amp;quot;,
    family = binomial(link = &amp;quot;logit&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready to add individual model specifications, each with their own data preprocessing pipeline to the model grid.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-the-first-model-specifications-to-the-model-grid&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding the first model specifications to the model grid&lt;/h3&gt;
&lt;p&gt;We will kick things off by adding the first model specification to my model grid. In this configuration I just apply our initial data preprocessing recipe and do no further. I will refer to this model as ‘baseline’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;baseline&amp;quot;, 
            x = initial_recipe)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One way of dealing with the potential drawbacks of the observed “collinearity clusters” is to apply a correlation filter. The correlation filter poses a heuristic approach to dealing with highly correlated predictors. It removes the predictors with the highest between-predictor correlations one at a time, until all between-predictor correlations are below some critical threshold.&lt;/p&gt;
&lt;p&gt;In order to do so, I extend my initial recipe with an additional step, that applies the correlation filter. Furthermore I will try out different values for the between-predictor correlation threshold value of the filter, essentially treating it as a hyperparameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.7&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .7)) %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.8&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .8)) %&amp;gt;%
  add_model(model_name = &amp;quot;corr_.9&amp;quot;, 
            x = initial_recipe %&amp;gt;%
              step_corr(all_predictors(), threshold = .9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The construction of these model specifications can - and indeed should - be parametrized. Especially if you want to try out a wider range of values for the ‘threshold’ parameter than just the three, that I have denoted here.&lt;/p&gt;
&lt;p&gt;Great, now we have a bunch of models specifications. We will train them right away and take a first look at the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train models.
models &amp;lt;- models %&amp;gt;% train(.)
# Display resampled performance statistics of the fitted models using standard 
# functionality from the &amp;#39;caret&amp;#39; package.
models$model_fits %&amp;gt;% resamples(.) %&amp;gt;% bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Judging by the resampled AUC performance statistics it seems, that there &lt;em&gt;could&lt;/em&gt; be a case for applying a correlation filter on the set of predictors. Apparently, the model with a correlation filter with a between-predictor correlation threshold value of .7 added to the data preprocessing pipeline yields the best median resampled AUC. Of the four models, this model is by far the least complex.&lt;/p&gt;
&lt;p&gt;We can see this by taking a look at the number of predictors, that were actually used in the final models (after removing variables with a correlation filter (if any)).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models$model_fits %&amp;gt;%
  map(pluck(c(&amp;quot;recipe&amp;quot;, &amp;quot;term_info&amp;quot;, &amp;quot;role&amp;quot;))) %&amp;gt;%
  map_int(~ sum(.x == &amp;quot;predictor&amp;quot;))
#&amp;gt; baseline  corr_.7  corr_.8  corr_.9 
#&amp;gt;      114       60       78       93&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ‘corr_.7’ model configuration only uses 60 predictors (after removal of highly correlated predictors), hence it only estimates 61 coefficients. In contrast the ‘baseline’ model uses all predictors (except the two variables with zero variances) and estimates 115 coefficients in total making it a much more complex model (by means of a higher variance) and more prone to the risk of overfitting.&lt;/p&gt;
&lt;p&gt;Overall it seems like applying a correlation filter with a correlation threshold value of 0.7 as part of the data preprocessing pipeline could be a good idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dimensionality-reduction-with-pca&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dimensionality reduction with PCA&lt;/h3&gt;
&lt;p&gt;Another approach to dealing with highly correlated predictors is to apply a Principal Component Analysis transformation of the predictors in order to reduce the dimensions of data set. You can read more about the PCA technique &lt;a href=&#34;https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This approach can be tested by tweaking my initial data preprocessing recipe once again with a couple of additional steps. Before actually conducting PCA, features are centered and scaled. This is completely standard.&lt;/p&gt;
&lt;p&gt;For the PCA transformation I vary the ‘threshold’ value, which is the fraction of the total variance of the predictors that should be covered by the components. The higher the value of ‘threshold’, the higher the number of components used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extend recipe with centering and scaling steps.
rec_center_scale &amp;lt;- initial_recipe %&amp;gt;%
  step_center(all_predictors()) %&amp;gt;%
  step_scale(all_predictors())

# Add model specifications with pca for dimensionality reduction.
models &amp;lt;- models %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.75&amp;quot;, 
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .75)) %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.85&amp;quot;,
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .85)) %&amp;gt;%
  add_model(model_name = &amp;quot;pca_.95&amp;quot;,
            x = rec_center_scale %&amp;gt;%
              step_pca(all_predictors(), threshold = .95))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us train the new model configurations and display the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- train(models)
models$model_fits %&amp;gt;% caret::resamples(.) %&amp;gt;% bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-24-tuning-a-data-preprocessing-pipeline-with-recipes-and-modelgrid_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Applying a data preprocessing pipeline with a PCA transformation capturing 95 pct. of the total variance of the set of predictors actually returns the highest resampled median value of AUC.&lt;/p&gt;
&lt;p&gt;You can look up, how many principal components that were used in the different model configurations in order to account for the desired amount of total variance of the predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models$model_fits[c(&amp;quot;pca_.75&amp;quot;, &amp;quot;pca_.85&amp;quot;, &amp;quot;pca_.95&amp;quot;)] %&amp;gt;%
  map(pluck(c(&amp;quot;recipe&amp;quot;, &amp;quot;term_info&amp;quot;, &amp;quot;role&amp;quot;))) %&amp;gt;%
  map_int(~ sum(.x == &amp;quot;predictor&amp;quot;))
#&amp;gt; pca_.75 pca_.85 pca_.95 
#&amp;gt;      22      34      58&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To summarize, adding a PCA transformation or a correlation filter to the data preprocessing pipeline seem like good ways of dealing with the “collinearity clusters” in the data set.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Experimenting with the data preprocessing pipeline can be seen as part of the model tuning process. Parameters of the data preprocessing pipeline can be thought of as tuning parameters.&lt;/li&gt;
&lt;li&gt;These kinds of experiments can be organized and conducted easily using R packages &lt;code&gt;recipes&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; in combination with &lt;code&gt;modelgrid&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-next&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;I have been thinking about how to extend the functionality of &lt;code&gt;modelgrid&lt;/code&gt; further in order to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parametrize experiments with the parameters of the data preprocessing pipeline. But actually I was under the impression, that others are working on developing similar functionality for tuning parameters of the data preprocessing pipeline. Am I wrong here?&lt;/li&gt;
&lt;li&gt;Support &lt;code&gt;parsnip&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;To expose models and model configurations from a model grid in a more ‘tidy’ way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Best, smaakagen&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>modelgrid - a framework for creating, managing and training multiple models</title>
      <link>/2018/07/14/modelgrid-a-framework-for-creating-managing-and-training-multiple-models/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/14/modelgrid-a-framework-for-creating-managing-and-training-multiple-models/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/modelgrid/index.html&#34;&gt;&lt;code&gt;modelgrid&lt;/code&gt;&lt;/a&gt; is a new package of mine, which has just made its way on to CRAN. &lt;code&gt;modelgrid&lt;/code&gt; offers a minimalistic but very flexible framework to create, manage and train a portfolio of &lt;a href=&#34;https://cran.r-project.org/web/packages/modelgrid/index.html&#34;&gt;&lt;code&gt;caret&lt;/code&gt;&lt;/a&gt; models. Note, you should already be fairly familiar with the &lt;code&gt;caret&lt;/code&gt; package before giving &lt;code&gt;modelgrid&lt;/code&gt; a spin.&lt;/p&gt;
&lt;p&gt;Below I describe the key concept behind &lt;code&gt;modelgrid&lt;/code&gt; as well as the features of &lt;code&gt;modelgrid&lt;/code&gt; divided into three main categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating a model grid&lt;/li&gt;
&lt;li&gt;Training a model grid&lt;/li&gt;
&lt;li&gt;Editing and removing models from a model grid&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After reading this post you should be able to grind models like never before using the &lt;code&gt;modelgrid&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;key-concept-behind-the-model-grid&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Key concept behind the model grid&lt;/h2&gt;
&lt;p&gt;When facing a Machine Learning problem, you typically want to try out a lot of models in order to find out, what works and what does not. But how can we manage these experiments in a structured, simple and transparent way? You guessed it - by using the &lt;code&gt;modelgrid&lt;/code&gt; package (and yes, I am already familiar with the &lt;code&gt;caretEnsemble&lt;/code&gt; package, but I wanted something, that was more flexible and easier/more intuitive to work with. Also I wanted a framework, that was pipe-friendly).&lt;/p&gt;
&lt;p&gt;A tuning grid consists of combinations of hyperparameters for a specific model. A model grid is just an extension of that concept in the sense that it consists of - potentially many - models, each with their own tuning grid. Basically the model grid is built by providing a set of shared settings, that by default will apply to all models within the model grid, and defining the settings for the individual models in the model grid.&lt;/p&gt;
&lt;p&gt;You can pre-allocate an empty model grid with the constructor function &lt;code&gt;model_grid&lt;/code&gt; and take a look at the structure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(modelgrid)
mg &amp;lt;- model_grid()

mg
#&amp;gt; $shared_settings
#&amp;gt; list()
#&amp;gt; 
#&amp;gt; $models
#&amp;gt; list()
#&amp;gt; 
#&amp;gt; $model_fits
#&amp;gt; list()
#&amp;gt; 
#&amp;gt; attr(,&amp;quot;class&amp;quot;)
#&amp;gt; [1] &amp;quot;model_grid&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An object belonging to the &lt;code&gt;model_grid&lt;/code&gt; class has three components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;shared_settings&lt;/code&gt;: these are the settings, that will be shared by all models in the model grid by default. Generally, it makes sense to keep some settings fixed for all models, e.g. the choice of target variable, features, resampling scheme and sometimes also preprocessing options. By providing them as shared settings the user avoids redundant code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;models&lt;/code&gt;: every individual model specification added to the model grid will be an element in this list. The individual model specification consists of settings that uniquely identify the indvidual model. If a setting has been set both as part of the shared settings and the settings of a given individual model specification, the setting from the individual model specification will apply for that given model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model_fits&lt;/code&gt;: this element contains the fitted models (one for each individual model specification), once the &lt;code&gt;model_grid&lt;/code&gt; has been trained.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-model-grid&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating a model grid&lt;/h2&gt;
&lt;p&gt;The first natural step of setting up the model grid is to define, which settings should be shared by all models by default. We will use the &lt;code&gt;GermanCredit&lt;/code&gt; data set from the &lt;code&gt;caret&lt;/code&gt; package as example data and do just that with the &lt;code&gt;share_settings&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(magrittr)
library(caret)
#&amp;gt; Warning: pakke &amp;#39;caret&amp;#39; blev bygget under R version 3.5.1
library(dplyr)
#&amp;gt; Warning: pakke &amp;#39;dplyr&amp;#39; blev bygget under R version 3.5.1
library(purrr)
# Load data on German credit applications.  
data(GermanCredit)

# Construct empty model grid and define shared settings.
mg &amp;lt;-
  model_grid() %&amp;gt;%
  share_settings(
    y = GermanCredit[[&amp;quot;Class&amp;quot;]],
    x = GermanCredit %&amp;gt;% select(-Class),
    preProc = &amp;quot;nzv&amp;quot;,
    metric = &amp;quot;ROC&amp;quot;,
    trControl = trainControl(
      method = &amp;quot;cv&amp;quot;,
      number = 5,
      summaryFunction = twoClassSummary,
      classProbs = TRUE
    )
  )

purrr::map_chr(mg$shared_settings, class)
#&amp;gt;            y            x      preProc       metric    trControl 
#&amp;gt;     &amp;quot;factor&amp;quot; &amp;quot;data.frame&amp;quot;  &amp;quot;character&amp;quot;  &amp;quot;character&amp;quot;       &amp;quot;list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;shared_settings&lt;/code&gt; component of the model grid is now populated. In order to complete the model grid we must define a set of individual model specifications, that we would like to give a shot. A common choice of baseline model could be a simple parametric model e.g. a Generalized Linear Model. The model specification is added to the model grid with the &lt;code&gt;add_model&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mg &amp;lt;- 
  mg %&amp;gt;%
  add_model(model_name = &amp;quot;Logistic Regression Baseline&amp;quot;,
            method = &amp;quot;glm&amp;quot;,
            family = binomial(link = &amp;quot;logit&amp;quot;))

mg$models
#&amp;gt; $`Logistic Regression Baseline`
#&amp;gt; $`Logistic Regression Baseline`$method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $`Logistic Regression Baseline`$family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;model_grid&lt;/code&gt; requires a (unique) name for each individual model specification, so I named this one ‘Logistic Regression Baseline’. If the user does not provide a name, a generic name - ‘Model[int]’ - is generated automatically.&lt;/p&gt;
&lt;p&gt;This is all it takes to create the smallest possible model grid with only one unique model configuration. The model grid can be trained with the &lt;code&gt;train&lt;/code&gt; function. For more on this go to ‘Training a model grid’.&lt;/p&gt;
&lt;p&gt;But a model grid with only one model specification is obviously not a really interesting use case. Let us insert another two model specifications into the model grid: a set of logistic regression models, only this time with the features being preprocessed with Principal Component Analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mg &amp;lt;- 
  mg %&amp;gt;%
  add_model(model_name = &amp;quot;Logistic Regression PCA&amp;quot;,
            method = &amp;quot;glm&amp;quot;,
            family = binomial(link = &amp;quot;logit&amp;quot;),
            preProc = c(&amp;quot;nzv&amp;quot;, &amp;quot;center&amp;quot;, &amp;quot;scale&amp;quot;, &amp;quot;pca&amp;quot;)) %&amp;gt;%
  add_model(model_name = &amp;quot;Logistic Regression PCA 98e-2&amp;quot;,
            method = &amp;quot;glm&amp;quot;,
            family = binomial(link = &amp;quot;logit&amp;quot;),
            preProc = c(&amp;quot;nzv&amp;quot;, &amp;quot;center&amp;quot;, &amp;quot;scale&amp;quot;, &amp;quot;pca&amp;quot;),
            custom_control = list(preProcOptions = list(thresh = 0.98)))
            
mg$models
#&amp;gt; $`Logistic Regression Baseline`
#&amp;gt; $`Logistic Regression Baseline`$method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $`Logistic Regression Baseline`$family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA`
#&amp;gt; $`Logistic Regression PCA`$method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA`$family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA`$preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;pca&amp;quot;   
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA 98e-2`
#&amp;gt; $`Logistic Regression PCA 98e-2`$method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA 98e-2`$family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA 98e-2`$preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;pca&amp;quot;   
#&amp;gt; 
#&amp;gt; $`Logistic Regression PCA 98e-2`$custom_control
#&amp;gt; $`Logistic Regression PCA 98e-2`$custom_control$preProcOptions
#&amp;gt; $`Logistic Regression PCA 98e-2`$custom_control$preProcOptions$thresh
#&amp;gt; [1] 0.98&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can of course add as many models as you like to the model grid with the &lt;code&gt;add_model&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;training-a-model-grid&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Training a model grid&lt;/h2&gt;
&lt;p&gt;The models from a model grid can be trained with the &lt;code&gt;train&lt;/code&gt; function from the &lt;code&gt;caret&lt;/code&gt; package, for which I have implemented a S3 method for the &lt;code&gt;model_grid&lt;/code&gt; class.&lt;/p&gt;
&lt;p&gt;When you call &lt;code&gt;train&lt;/code&gt; with a &lt;code&gt;model_grid&lt;/code&gt;, all of the individual model specifications are consolidated with the shared settings into complete &lt;code&gt;caret&lt;/code&gt; model specifications, which are then trained one by one with &lt;code&gt;caret&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;consolidation-of-settings-into-complete-model-specifications&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Consolidation of settings into complete model specifications&lt;/h3&gt;
&lt;p&gt;For a given model the model settings are consolidated with the &lt;code&gt;consolidate_model&lt;/code&gt; function. Let us see how this works with the three models. For the baseline model there is no overlap between the shared settings and the settings in the individual model specification, and hence the settings will just be appended into one configuration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# there are no conflicts.
dplyr::intersect(names(mg$shared_settings), names(mg$models$`Logistic Regression Baseline`))
#&amp;gt; character(0)

# consolidate model settings into one model.
consolidate_model(
  mg$shared_settings, 
  mg$models$`Logistic Regression Baseline`
  ) %&amp;gt;%
  purrr::map_chr(class)
#&amp;gt;       method       family            y            x      preProc 
#&amp;gt;  &amp;quot;character&amp;quot;     &amp;quot;family&amp;quot;     &amp;quot;factor&amp;quot; &amp;quot;data.frame&amp;quot;  &amp;quot;character&amp;quot; 
#&amp;gt;       metric    trControl 
#&amp;gt;  &amp;quot;character&amp;quot;       &amp;quot;list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In case the same setting has been specified both in the shared settings of the model grid and in the individual settings for a specific model, the individual setting will apply. This is the case for the model ‘Logistic Regression PCA’, where the ‘preProc’ argument has also been defined in the model specific configuration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the &amp;#39;preProc&amp;#39; setting is defined both in the shared and model specific settings.
dplyr::intersect(names(mg$shared_settings), names(mg$models$`Logistic Regression PCA`))
#&amp;gt; [1] &amp;quot;preProc&amp;quot;

mg$shared_settings$preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;
mg$models$`Logistic Regression PCA`$preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;pca&amp;quot;

# consolidate model settings into one model.
consolidate_model(
  mg$shared_settings, 
  mg$models$`Logistic Regression PCA`
  ) %&amp;gt;%
  magrittr::extract2(&amp;quot;preProc&amp;quot;)
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;pca&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, if the ‘trControl’ argument is defined as part of the shared settings, the subsettings of ‘trControl’ can be modified for a specific model with the special setting ‘custom_control’ (which itself is given as an explicit argument to the &lt;code&gt;add_model&lt;/code&gt; function) in the model specific settings.&lt;/p&gt;
&lt;p&gt;For the model ‘Logistic Regression PCA 98e-2’, the preprocessing options for PCA were adjusted with ‘custom_control’. When the model is consolidated, the model specific customizations of subsettings of the shared ‘trControl’ argument will apply.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the &amp;#39;trControl$preProcOptions$thresh&amp;#39; setting is defined in the shared
# settings but customized in the model specific settings.
mg$shared_settings$trControl$preProcOptions$thresh
#&amp;gt; [1] 0.95
mg$models$`Logistic Regression PCA 98e-2`$custom_control$preProcOptions$thresh
#&amp;gt; [1] 0.98

# consolidate model settings into one model.
consolidate_model(
  mg$shared_settings, 
  mg$models$`Logistic Regression PCA 98e-2`
  ) %&amp;gt;%
  magrittr::extract2(c(&amp;quot;trControl&amp;quot;, &amp;quot;preProcOptions&amp;quot;, &amp;quot;thresh&amp;quot;))
#&amp;gt; [1] 0.98&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-training&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model training&lt;/h3&gt;
&lt;p&gt;When calling the &lt;code&gt;train&lt;/code&gt; function, the &lt;code&gt;consolidate_model&lt;/code&gt; function is called under the hood with all of the individual models and the shared settings, and a set of complete &lt;code&gt;caret&lt;/code&gt; model specifications is generated - one for each individual model specification.&lt;/p&gt;
&lt;p&gt;Afterwards the models are trained one by one with &lt;code&gt;caret&lt;/code&gt;, and the fitted models are saved in the &lt;code&gt;model_fits&lt;/code&gt; component of the model grid.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# train models from model grid.
mg &amp;lt;- train(mg)

# the fitted models now appear in the &amp;#39;model_fits&amp;#39; component.
names(mg$model_fits)
#&amp;gt; [1] &amp;quot;Logistic Regression Baseline&amp;quot;  &amp;quot;Logistic Regression PCA&amp;quot;      
#&amp;gt; [3] &amp;quot;Logistic Regression PCA 98e-2&amp;quot;

# extract performance.
mg$model_fits %&amp;gt;%
  caret::resamples(.) %&amp;gt;%
  lattice::bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-07-14-modelgrid-a-framework-for-creating-managing-and-training-multiple-models_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we now add an additional models to the model grid, and call &lt;code&gt;train&lt;/code&gt; on the model grid again, only the new models (those that do not yet have a fit) will be trained by default.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# train models from model grid.
mg &amp;lt;- 
  mg %&amp;gt;%
  add_model(model_name = &amp;quot;Funky Forest&amp;quot;,
            method = &amp;quot;rf&amp;quot;) %&amp;gt;%
  train(.)

mg$model_fits %&amp;gt;%
  caret::resamples(.) %&amp;gt;%
  lattice::bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-07-14-modelgrid-a-framework-for-creating-managing-and-training-multiple-models_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you call &lt;code&gt;train&lt;/code&gt; with the ‘train_all’ argument set to &lt;code&gt;TRUE&lt;/code&gt;, all models will be trained regardless.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;support-for-all-train-interfaces&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Support for all train interfaces&lt;/h3&gt;
&lt;p&gt;The training of a &lt;code&gt;model_grid&lt;/code&gt; supports both the explicit ‘x’, ‘y’ interface to train, the ‘formula’ interface and last but not least the new powerful ‘recipe’ interface. Let us try out the latter. First we will create a basic recipe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create basic recipe.
library(recipes)
rec &amp;lt;- 
  recipe(GermanCredit, formula = Class ~ .) %&amp;gt;%
  step_nzv(all_predictors())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that as a starting point I will create and train a minimal model grid as an example. I will tweak the recipe for one of the models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mg_rec &amp;lt;-
  model_grid() %&amp;gt;%
  share_settings(
    metric = &amp;quot;ROC&amp;quot;,
    data = GermanCredit,
    trControl = trainControl(
      method = &amp;quot;cv&amp;quot;,
      number = 5,
      summaryFunction = twoClassSummary,
      classProbs = TRUE
    )
  ) %&amp;gt;%
  add_model(
    model_name = &amp;quot;Log Reg&amp;quot;,
    x = rec,
    method = &amp;quot;glm&amp;quot;,
    family = binomial(link = &amp;quot;logit&amp;quot;)
  ) %&amp;gt;%
  add_model(
    model_name = &amp;quot;Log Reg PCA&amp;quot;,
    x = rec %&amp;gt;%
      step_center(all_predictors()) %&amp;gt;%
      step_scale(all_predictors()) %&amp;gt;%
      step_pca(all_predictors()),
    method = &amp;quot;glm&amp;quot;,
    family = binomial(link = &amp;quot;logit&amp;quot;)
  ) %&amp;gt;%
  train(.)

mg_rec$model_fits %&amp;gt;%
  caret::resamples(.) %&amp;gt;%
  lattice::bwplot(.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-07-14-modelgrid-a-framework-for-creating-managing-and-training-multiple-models_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;editing-and-removing-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Editing and removing models&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;modelgrid&lt;/code&gt; has a couple of functions, that makes it easy to work iteratively with the model specifications in a model grid. If you want to modify an existing model configuration, please use the &lt;code&gt;edit_model&lt;/code&gt; function. Below I use it to modify one of the generalized linear models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# existing model configuration.
mg$models$`Logistic Regression PCA`
#&amp;gt; $method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;pca&amp;quot;

# edit model configuration.
mg &amp;lt;-
  mg %&amp;gt;%
  edit_model(model_name = &amp;quot;Logistic Regression PCA&amp;quot;,
             preProc = c(&amp;quot;nzv&amp;quot;, &amp;quot;center&amp;quot;, &amp;quot;scale&amp;quot;, &amp;quot;ICA&amp;quot;))
#&amp;gt; Model fit for Logistic Regression PCA has been deleted.

mg$models$`Logistic Regression PCA`
#&amp;gt; $method
#&amp;gt; [1] &amp;quot;glm&amp;quot;
#&amp;gt; 
#&amp;gt; $family
#&amp;gt; 
#&amp;gt; Family: binomial 
#&amp;gt; Link function: logit 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $preProc
#&amp;gt; [1] &amp;quot;nzv&amp;quot;    &amp;quot;center&amp;quot; &amp;quot;scale&amp;quot;  &amp;quot;ICA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you see, when you modify an existing model specification, any corresponding fitted model is deleted, so that everything is in sync.&lt;/p&gt;
&lt;p&gt;You can also remove a model specification (including any fitted model) from the model grid with the &lt;code&gt;remove_model&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(mg$models)
#&amp;gt; [1] &amp;quot;Funky Forest&amp;quot;                  &amp;quot;Logistic Regression Baseline&amp;quot; 
#&amp;gt; [3] &amp;quot;Logistic Regression PCA 98e-2&amp;quot; &amp;quot;Logistic Regression PCA&amp;quot;

# remove model configuration.
mg &amp;lt;-
  mg %&amp;gt;%
  remove_model(&amp;quot;Funky Forest&amp;quot;)
#&amp;gt; Model fit for Funky Forest has been deleted.

names(mg$models)
#&amp;gt; [1] &amp;quot;Logistic Regression Baseline&amp;quot;  &amp;quot;Logistic Regression PCA 98e-2&amp;quot;
#&amp;gt; [3] &amp;quot;Logistic Regression PCA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it! You should now be all set to grind models with the &lt;code&gt;modelgrid&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Peace out&lt;/p&gt;
&lt;p&gt;/smaakagen&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>